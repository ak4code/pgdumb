# PgDumb - парсинг pg_dump -Fc

[![Python](https://img.shields.io/badge/python-3.7%2B-blue)](https://www.python.org/downloads/)

## Цель исследования  
Разобраться в структуре custom-формата pg_dump (`-Fc`) и оценить возможность реализации потокового парсинга с модификацией данных без полной загрузки дампа в оперативную память.

## Ключевые выводы

### 1. Структура custom-формата pg_dump  
Формат является бинарным и начинается с сигнатуры `PGDMP`. Он состоит из трех основных частей:  
- **Заголовок (Header)**: Фиксированного размера блок в начале файла, содержащий метаданные о дампе.  
  - **Содержимое**:  
    - Сигнатура (`PGDMP`, 5 байт).  
    - Версия формата (например, 1.12–1.16).  
    - Версия PostgreSQL.  
    - Временная метка создания дампа.  
    - Флаги сжатия (например, использование `zlib`).  
    - Дополнительные метаданные (например, имя базы данных).  
  - **Назначение**: Идентифицирует файл как дамп pg_dump и предоставляет параметры для дальнейшей обработки.  

- **TOC (Table of Contents)**: Переменного размера каталог, содержащий список всех объектов дампа (таблицы, схемы, индексы, триггеры, BLOB-объекты, комментарии и т.д.).  
  - **Содержимое**:  
    - Список записей TOC, каждая из которых описывает объект:  
      - **Идентификатор объекта** (`dump_id`): Уникальный идентификатор объекта в дампе.  
      - **Тип объекта** (`desc`): Тип объекта, например, `TABLE`, `INDEX`, `TABLE DATA`, `BLOB`, `COMMENT`.  
      - **Метаданные**:  
        - Имя объекта (`tag`).  
        - Схема (`namespace`).  
        - Пространство таблиц (`tablespace`).  
        - Владелец (`owner`).  
        - SQL-определения:  
          - `defn`: Определение объекта (например, `CREATE TABLE` или `COMMENT ON COLUMN`).  
          - `drop_stmt`: Команда удаления объекта (например, `DROP TABLE`).  
          - `copy_stmt`: Команда для загрузки данных (например, `COPY`).  
        - `tableam` (для версий 1.14+, Table Access Method).  
        - Зависимости (список `dump_id` других объектов).  
      - **data_state**: Состояние данных объекта, определяющее способ их расположения:  
        - `0`: Данные отсутствуют (например, для схем, индексов, комментариев).  
        - `1`: Данные расположены последовательно в потоке (обычно в потоковом режиме).  
        - `2`: Данные имеют определенное смещение (`offset`) в файле (обычно при записи в файл).  
        - `3`: Данные представлены в виде SQL-команд (например, `COPY`, `INSERT`, `CREATE TABLE`, `COMMENT ON COLUMN`).  
      - **offset**: Смещение в файле, где хранятся данные объекта (для `data_state = 2`).  
      - **section**: Указывает этап обработки объекта при восстановлении дампа:  
        - `SECTION_PRE_DATA`: Объекты, создаваемые до загрузки данных (например, схемы, таблицы, типы).  
        - `SECTION_DATA`: Объекты, содержащие данные или их определения (например, данные таблиц, BLOB, определения таблиц с `CREATE TABLE`, комментарии с `COMMENT ON COLUMN`).  
        - `SECTION_POST_DATA`: Объекты, создаваемые после загрузки данных (например, индексы, триггеры, ограничения).  
        - `SECTION_NONE`: Объекты, не привязанные к конкретному этапу (например, процедурные объекты).  
  - **Назначение**:  
    - Обеспечивает навигацию по дампу, позволяя быстро находить и обрабатывать объекты.  
    - Определяет порядок восстановления объектов (через `section`), чтобы соблюсти зависимости.  
    - Хранит метаданные для выборочного восстановления (например, только данные определенной таблицы).  
    - В `SECTION_DATA` может содержать SQL-определения (например, `CREATE TABLE public.table_name` или `COMMENT ON COLUMN public.table_name.name ...`), если `data_state = 3`.  

- **Блоки данных**: Последовательность блоков, содержащих данные объектов (таблиц, BLOB-объектов и т.д.).  
  - Типы блоков:  
    - `BLK_DATA (0x01)`: Данные таблиц, сжатые или несжатые.  
    - `BLK_BLOBS (0x02)`: Большие бинарные объекты (BLOB).  
    - `BLK_END (0x04)`: Маркер завершения дампа.  

### 2. Значения `data_state` и их использование  
Поле `data_state` в записях TOC определяет, как хранятся данные объекта:  
- **`0`**: Данные отсутствуют. Используется для объектов, не содержащих данных (например, схемы, индексы, комментарии с `data_state = 0`).  
- **`1`**: Данные расположены последовательно в потоке. Используется в потоковом режиме (например, `pg_dump -Fc | pg_restore`).  
- **`2`**: Данные имеют определенное смещение (`offset`) в файле. Используется при создании дампа в файл (например, `pg_dump -Fc > dumpfile`).  
- **`3`**: Данные представлены в виде SQL-команд. Используется для текстового представления данных (например, `COPY`, `INSERT`) или определений объектов (например, `CREATE TABLE`, `COMMENT ON COLUMN`).  

**Почему `data_state` различается?**  
- При дампе в файл (`data_state = 2`):  
  - Данные сохраняются с указанием смещения (`offset`) в TOC, что позволяет произвольный доступ.  
- При потоковой передаче (`data_state = 1`):  
  - Данные передаются последовательно, без указания смещений, для линейной обработки.  
- Для `data_state = 3`:  
  - Данные хранятся как SQL-команды прямо в TOCEnties, включая `CREATE TABLE` (например, для таблицы `public.table_name`) и `COMMENT ON COLUMN` (например, комментарии к столбцам таблицы).  
  - Это упрощает модификацию, например, обфускацию текста комментариев.  

**Обработка `COMMENT ON COLUMN` в `SECTION_DATA`**:  
- Комментарии (`COMMENT ON COLUMN`) могут быть включены в `SECTION_DATA` с `data_state = 3`, особенно если они связаны с определением таблицы или данными.  
- Например, строка `defn` может содержать `COMMENT ON COLUMN ...`, которую необходимо использовать как правило для обфускации.   

### 3. Потоковая обработка  
- Реализован алгоритм последовательного чтения:  
  - **Заголовок**: Читается однократно благодаря фиксированному размеру.  
  - **TOC**: Парсится для определения структуры дампа  
  - **Блоки данных**: Обрабатываются по мере чтения, с учетом компрессии (пока что только zlib):  
- Используется декомпрессия данных "на лету" с использованием `zlib`.  
- Используется буферизация для минимизации потребления памяти.  

### 4. Модификация данных и обфускация  
- Доказана возможность потоковой модификации:  
  - Декомпрессия блока данных.  
  - Модификация содержимого (например, замена строк в данных).  
  - Повторная компрессия и запись в новый файл или поток.    

## Проблемы и ограничения  
1. **Отсутствие обработки BLOB-объектов**  
   - Текущая результаты исследования не поддерживают парсинг и модификацию блоков `BLK_BLOBS`.  
   - Требуется доработка для работы с большими бинарными объектами.  
2. **Обработка больших блоков данных**
   - В текущей реализации обрабатывается только один блок данных, исследование проводилось на одной таблице из-за большого объема дампа.
   - Блоки размером более 1 ГБ могут вызывать проблемы с производительностью и управлением памятью.  
   - Необходима оптимизация алгоритма для больших объемов данных.  
3. **Ограниченная поддержка сжатия**  
   - Поддерживается только алгоритм `zlib`.  
   - Отсутствует поддержка других алгоритмов сжатия (необязательно, по умолчанию хватает `zlib`).  
4. **Обработка `COMMENT ON COLUMN`**  
   - Требуется доработка для извлечения правил для обфускации.  

## Заключение  
Проведенное исследование подтвердило возможность реализации потокового парсинга и модификации pg_dump архивов в custom-формате. 

**Ключевые достижения:**
 - Обработан механизм чтения заголовка и TOC
 - Реализована поддержка потоковой обработки данных таблиц
 - Доказана работоспособность концепции "модификации на лету", но пока только на одной таблице
 
**Для промышленного использования система требует доработки в области:**
 - Поддержки всех типов блоко (BLK_BLOBS, BLK_END)
 - Обработки экстремально больших дампов
 - Передачи данных в pg_stage для обфускации
 
Ссылки:
https://github.com/gmr/pgdumplib - либа для чтения custom дампов на python
https://github.com/wichert/pgarchive - либа для чтения custom дампов на rust
https://doxygen.postgresql.org/dir_d5a96fbb673152a70c7ff3e7a4f76640.html - исходный код pg_dump
